{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Connect to Neo4j Database\n",
    "uri = \"bolt://localhost:7687\"  # Adjust if needed\n",
    "username = \"neo4j\"  # Your username\n",
    "password = \"test_password\"  # Your password\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to fetch user-article interactions, article-tags, and article-category relationships\n",
    "def fetch_data_from_neo4j():\n",
    "    query = \"\"\"\n",
    "    MATCH (u:User)-[r:READ]->(a:Article)\n",
    "    MATCH (a)-[t:HAS_TAG]->(tag:Tag)\n",
    "    MATCH (a)-[c:BELONGS_TO]->(category:Category)\n",
    "    RETURN u.id AS user_id, a.url AS article_url, r.timeSpent AS timeSpent,\n",
    "           collect(tag.name) AS tags, collect(category.name) AS categories\n",
    "    \"\"\"\n",
    "    \n",
    "    session = driver.session()\n",
    "    result = session.run(query)\n",
    "    \n",
    "    user_article_data = []\n",
    "    for record in result:\n",
    "        user_article_data.append({\n",
    "            \"user_id\": record[\"user_id\"],\n",
    "            \"article_url\": record[\"article_url\"],\n",
    "            \"read_time\": record[\"timeSpent\"],\n",
    "            \"tags\": record[\"tags\"],\n",
    "            \"categories\": record[\"categories\"]\n",
    "        })\n",
    "    \n",
    "    session.close()\n",
    "    return user_article_data\n",
    "\n",
    "# Example of fetching data from Neo4j\n",
    "user_article_data = fetch_data_from_neo4j()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_graphsage(user_article_data):\n",
    "    user_map = {}\n",
    "    article_map = {}\n",
    "    tag_map = {}\n",
    "    category_map = {}\n",
    "    edges = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    # Create mappings for users, articles, tags, categories\n",
    "    for idx, data in enumerate(user_article_data):\n",
    "        if data[\"user_id\"] not in user_map:\n",
    "            user_map[data[\"user_id\"]] = len(user_map)\n",
    "        if data[\"article_url\"] not in article_map:\n",
    "            article_map[data[\"article_url\"]] = len(article_map)\n",
    "        \n",
    "        # Create edge between user and article (with read_time as edge attribute)\n",
    "        edges.append((user_map[data[\"user_id\"]], article_map[data[\"article_url\"]]))\n",
    "        edge_attr.append([data[\"read_time\"]])  # Read time\n",
    "        \n",
    "        # Create edges between article and tags\n",
    "        for tag in data[\"tags\"]:\n",
    "            if tag not in tag_map:\n",
    "                tag_map[tag] = len(tag_map)\n",
    "            edges.append((article_map[data[\"article_url\"]], tag_map[tag]))\n",
    "            edge_attr.append([1])  # Assuming a simple binary weight for tags\n",
    "        \n",
    "        # Create edges between article and category\n",
    "        for category in data[\"categories\"]:\n",
    "            if category not in category_map:\n",
    "                category_map[category] = len(category_map)\n",
    "            edges.append((article_map[data[\"article_url\"]], category_map[category]))\n",
    "            edge_attr.append([1])  # Binary weight for category\n",
    "\n",
    "    # Convert edges to 2D tensor (shape: [2, num_edges])\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # Ensure it's 2D [2, num_edges]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)  # Edge attributes\n",
    "    \n",
    "    # Create dummy node features (identity matrix for now)\n",
    "    num_nodes = len(user_map) + len(article_map) + len(tag_map) + len(category_map)\n",
    "    x = torch.eye(num_nodes, dtype=torch.float)  # Identity matrix as features\n",
    "\n",
    "    # Create Data object (PyTorch Geometric's format)\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    return user_map, article_map, tag_map, category_map, data\n",
    "\n",
    "# Prepare data for GraphSAGE\n",
    "user_map, article_map, tag_map, category_map, data = prepare_data_for_graphsage(user_article_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_graphsage(user_article_data, num_epochs=10):\n",
    "    # Prepare data\n",
    "    user_map, article_map, tag_map, category_map, data = prepare_data_for_graphsage(user_article_data)\n",
    "    \n",
    "    # Create GraphSAGE model\n",
    "    model = GraphSAGE(in_channels=data.x.size(1), hidden_channels=32, out_channels=128)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data)  # Forward pass\n",
    "        \n",
    "        # Cosine similarity between user embeddings and article embeddings\n",
    "        user_embeddings = out[:len(user_map)]\n",
    "        article_embeddings = out[len(user_map):len(user_map) + len(article_map)]\n",
    "\n",
    "        # Compute cosine similarity between user and article embeddings\n",
    "        similarity_matrix = torch.matmul(user_embeddings, article_embeddings.t())  # [num_users, num_articles]\n",
    "\n",
    "        # Now, you need to compare similarity_matrix with the ground truth\n",
    "        # This part depends on your dataset. For example, you could compute a binary cross-entropy loss\n",
    "        # with a label indicating whether a user has read an article or not.\n",
    "\n",
    "        # Assuming you have a binary label (0 or 1) for each (user, article) pair\n",
    "        labels = torch.tensor([[1 if (user, article) in user_article_data else 0\n",
    "                               for article in article_map] for user in user_map])\n",
    "\n",
    "        # Compute binary cross-entropy loss\n",
    "        loss = F.binary_cross_entropy_with_logits(similarity_matrix, labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, user_map, article_map, tag_map, category_map, data\n",
    "\n",
    "model, user_map, article_map, tag_map, category_map, data = train_graphsage(user_article_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended articles for user1: ['https://www.thehindu.com/news/national/telangana/ten-years-after-the-creation-of-a-separate-telangana-dividing-a-culture/article68282827.ece', 'https://www.thehindu.com/sci-tech/technology/googles-ai-chatbot-gemini-verbally-abused-user-told-them-to-die-report/article68871570.ece', 'https://www.thehindu.com/news/cities/Delhi/delhi-air-pollution-cm-atishi-announces-staggered-timings-for-govt-offices-to-tackle-traffic-congestion/article68871906.ece']\n"
     ]
    }
   ],
   "source": [
    "def make_recommendations(model, data, user_map, article_map, top_k=3):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get node embeddings from the model\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "    \n",
    "    # Recommend articles for a specific user\n",
    "    user_id = \"user456\"  # Change this based on your needs\n",
    "    user_idx = user_map[user_id]\n",
    "    \n",
    "    # Get the user's node embedding\n",
    "    user_embedding = out[user_idx]\n",
    "    \n",
    "    # Calculate similarity between the user and all articles (cosine similarity)\n",
    "    article_embeddings = out[len(user_map):len(user_map)+len(article_map)]  # Article nodes\n",
    "    \n",
    "    similarities = torch.matmul(user_embedding, article_embeddings.t())  # Cosine similarity\n",
    "    top_articles = similarities.topk(top_k).indices\n",
    "    \n",
    "    # Map article indices back to URLs\n",
    "    recommended_articles = [list(article_map.keys())[i] for i in top_articles]\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Make recommendations for user1\n",
    "recommended_articles = make_recommendations(model, data, user_map, article_map, top_k=3)\n",
    "print(f\"Recommended articles for user1: {recommended_articles}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
